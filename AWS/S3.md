# S3

## Overview

Use cases:

- Backup and storage
- Disaster recovery
- Archive
- Hybrid Cloud Storage (you have storage on-premise that you want to expand)
- Application hosting
- Media hosting
- Data lakes & big data analysis
- Software delivery
- Static website

S3 allows people to store **objects** (files) in **buckets** (directories). **Buckets must have globally unique name** (across all regions and accounts). Because of this restriction most common mistake is to think of your bucket on a global level but in fact **buckets are defined at the region level**.

Namingg convention:

- No uppercase
- No underscore
- Must start with letter or number
- NOT start with **xn--**
- NOT end with **-s3alias**
- 3-63 characters long
- Not an IP

**Objects** are files and they **are identified with a key**. **Key is full path to your object** and it is composed of `prefix + object name`, example `s3://my-bucket/dir/subdir/file.txt`, here prefix is `dir/subdir/` and object name is `file.txt` and together they are key.

This way of writing indicates there are directories on S3 which is not true. S3 is key value type of storage where key is just a long name.

Object value can be anything you want to upload, and **maximum size of an object is 5TB**, however **if file** you want to upload **is greater than 5GB you must use multi-part upload**.

Objects can have:

- metadata - list of key/value pairs set by user or system
- tags - up to 10 unicode key/value pairs, useful for security/lifecycle
- version id

## Security

Security can be **User-Based**, **Resource-Based** and **Encryption**

User-Based security is done through IAM policies that define which API calls should be allowed for specific user.

Resource-Based security is done through:

- Bucket policies
- Object access control list (ACL)
- Bucket access control list (ACL)

_Note: IAM principal can access an S3 object if user IAM permission allows it or resource policy allows it and there is no explicit deny._

### Bucket Policies

These policies are JSON based, and have following key properties:

- Resource - ARN array of bucket and objects
- Effect - Allow or Deny
- Actions - array of API actions to Allow or Deny
- Principal - The account or user to apply policy to (\* for everyone)

We can use this policy to **grant public access** to the bucket, **grant access to another account** or **force objects to be encrypted at upload**.

When granting public access bucket policy is not enough. You need to change **Block Public Access** setting as well because it is set to true by default. This is extra level of protection set by Amazon to make data leaks harder to achieve.

## Website

S3 can be used to host static websites and have them accessible on the internet. This won't work if you have public access blocked and will return 403 Forbidden error.

## Versioning

When you upload a file with name that already exists, new object will overwrite existing file. Versioning is a feature that protects against unintended deletes or overwrites and provides you with an easy way to roll back to previous version of you file/object.

You can enable this feature on a bucket level and any file that is not versioned prior to enabling will have version set to `null`. Suspending versioning does not delete previos versions, so its safe operation.

When versioning is enabled and you delete a file, that file would not actually be deleted, instead a delete marker would be placed on it. To revert deletion you need to delete that delete marker.

## Replication

There are two types of replication CRR (cross region replication) and SRR (same region replication). To enable asynchronous replication we need to have target bucket (in other region for CRR) and enable versioning for both source and target bucket. These buckets can be in different AWS accounts.

After you enable replication, only new objects are replicated. To replicate existing object you can use **S3 Batch Replication**.

Deletes are not replicated across these buckets, the only thing you can replicate are delete markers but even that requires explicit configuration,

Use cases:

- CRR - compliance, lower latency access, replication across acounts
- SRR - log aggregation, live replication between production and test accounts

## Storage classes

- Amazon S3 Standard - General Purpose
- Amazon S3 Standard - Infrequent Access (IA)
- Amazon S3 One Zone - Infrequent Access (IA)
- Amazon S3 Glacier Instant Retrieval
- Amazon S3 Glacier Flexible Retrieval
- Amazon S3 Glacier Deep Archive
- Amazon S3 Intelligent Tiering

You can move between classes manually or by using S3 lifecycle configurations.

### Durability and Availablity

**Durability represents how many times object is going to be lost by Amazon S3**. Amazon S3 has high durability and its called eleven nines (11 9s, 99,999999999%), this means that if you store 10 milion objects you can on average expect to lose single object once every 10000 years. This figure is true across all classes.

**Availability stands for how ready service is**. This varies depending on storage class, for example S3 standard is available 99.99% of time, which means that you can expect it to have 53 minutes of downtime a year.

### S3 Standard - General Purpose

- 99.99% Availablity
- Used for frequent data access
- Low latency and high throughput
- It can sustain 2 concurrent Amazon facility failures.

This is used for: big data analytics, mobile and gaming applications, content distribution...

### S3 Infrequent Access

This is used for data that is not accessed frequently, but requires rapid access when needed, like backups and disaster recovery. It costs lower than S3 standard but it costs to retrieve data.

S3 Standard - Infrequent Access (IA):

- 99.9% Availablity (a bit less)

S3 One Zone - Infrequent Access (IA):

- High durability in single AZ (data is lost when AZ is destroyed)
- 99.5% Availablity

### S3 Glacier

This is lookup storage meant for archive and backup, you get priced for retrieving objects (like IA).

S3 Glacier Instant Retrieval:

- Milisecond retrieval
- Minimum storage duration of 90 days

S3 Glacier Flexible Retrieval (formerly Amazon S3 Glacier):

- Retrieval
  - Expedited (1 to 5 minutes)
  - Standard (3 to 5 hours)
  - Bulk (5 - 12 hours) **free**
- Minimum storage duration of 90 days

S3 Glacier Deep Archive:

- Retrieval
  - Standard (12 hours)
  - Bulk (48 hours)
- Minimum storage duration of 180 days

### S3 Intelligent Tiering

It **moves objects automatically between access tiers based on usage**, and there are **no charges for object retrieval, but there are charges for monitoring and auto-tiering**.

- Frequent Access tier (automatic) - default
- Infrequent Access tier (automatic) - objects not accessed for 30 days
- Archive Instant Access tier (automatic) - objects not accessed for 90 days
- Archive Access tier (optional) - objects not accessed from 90 days to 700+ days
- Deep Archive Access tier (optional) - objects not accessed from 180 days to 700+ days
